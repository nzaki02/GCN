{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gcn_community_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYhdvwTkWs-l"
      },
      "source": [
        "# **Overlapping Community Detection in Protein-protein interaction network with GCN**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-esDSd5DzV_7"
      },
      "source": [
        "Upload the files PPI-Net.txt and Original-Communities.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCn5JrBTo65I"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbjUPx9gJHI"
      },
      "source": [
        "**Import all the necessary libraries, paths, and constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh9imyrinEBG"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import math\r\n",
        "import random\r\n",
        "#define path of graph file and communities file\r\n",
        "labelfile = '/content/Original-Communities.txt'\r\n",
        "graphfile =  '/content/PPI-Net.txt'\r\n",
        "#select number of communities with maximum members\r\n",
        "n = 10 "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NipxRupCfo5W"
      },
      "source": [
        "**Function for loading data from graph file and ground truth file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgDY7XrhnKei"
      },
      "source": [
        "def loadData(labelfile, graphfile):\r\n",
        "  data = []\r\n",
        "  n_communities = []\r\n",
        "  #save all communities in list-data regardless of the order\r\n",
        "  with open(labelfile) as inputfile:\r\n",
        "      for line in inputfile:\r\n",
        "          data.append(line.split())\r\n",
        "  graph = {}\r\n",
        "  #save n communities with maximum members in list-n_communities keeping the decreasing order of length\r\n",
        "  for i in range(n):\r\n",
        "    p = max(data,key=len)\r\n",
        "    n_communities.append(p)\r\n",
        "    data.remove(p)\r\n",
        "  with open(graphfile) as inputfile:\r\n",
        "        for line in inputfile:\r\n",
        "            node = line.split()[0]#read 1st element in any column(node 1)\r\n",
        "            neigh = line.split()[1]#read 2nd element in any column(node 2)\r\n",
        "            #Not include those nodes, which are not in n_communities\r\n",
        "            g = 0\r\n",
        "            for i in range(len(n_communities)):\r\n",
        "               if( node in n_communities[i]):\r\n",
        "                     g=1\r\n",
        "            if g==0:\r\n",
        "              continue\r\n",
        "            g1=0\r\n",
        "            for i in range(len(n_communities)):\r\n",
        "               if( neigh in n_communities[i]):\r\n",
        "                     g1=1\r\n",
        "            if g1==0:\r\n",
        "              continue\r\n",
        "            #save all the nodes and edges, which are common to the graphfile and n_communities\r\n",
        "            if node in graph:\r\n",
        "                graph[node].add(neigh)\r\n",
        "            else:\r\n",
        "                graph[node] = {neigh}\r\n",
        "            if neigh in graph:\r\n",
        "                graph[neigh].add(node)\r\n",
        "            else:\r\n",
        "                graph[neigh] = {node}\r\n",
        "  return n_communities, graph"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DALv7lISiYlm"
      },
      "source": [
        "*The below function will output a one-hot-encoder label for every node. It takes a list of all the communities having a particular node as the member. If n = 5, the length of this one hot encoder will be 31, which covers the possibility of nodes belonging to atleast one community out of 5..*\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIygWWN2iX9v"
      },
      "source": [
        "def labeller(pos):\r\n",
        "  p = [0]*n\r\n",
        "  for i in pos:\r\n",
        "     p[i]=1\r\n",
        "  strings = [str(integer) for integer in p]\r\n",
        "  a_string = \"\".join(strings)\r\n",
        "  label = [0]*(2**n-1)\r\n",
        "  label[int(a_string, 2)]=1\r\n",
        "  return  label"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkLJZDbCk-_W"
      },
      "source": [
        "**Preparing adjacency matrix, degree Matrix, and labels of nodes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLhKUqsLlNXF"
      },
      "source": [
        "def preprocessingData(graph, n_communities):\r\n",
        "  adj_matrix = np.zeros((len(graph), len(graph)))\r\n",
        "  degree_matrix = np.zeros((len(graph), len(graph)))\r\n",
        "  node_index = {}\r\n",
        "  j = 0\r\n",
        "  for i in graph:\r\n",
        "    node_index[i] = j\r\n",
        "    j += 1\r\n",
        "  for i in node_index:\r\n",
        "    for j in graph[i]:\r\n",
        "      if(j in node_index):\r\n",
        "        adj_matrix[node_index[i]][node_index[j]] = 1\r\n",
        "    degree_matrix[node_index[i]][node_index[i]] = len(graph[i])\r\n",
        "  label = np.zeros((len(graph), 2**n-1))\r\n",
        "  for nodeId in node_index:\r\n",
        "    u=[]\r\n",
        "    for i in n_communities:\r\n",
        "      if nodeId in i:\r\n",
        "        u.append(n_communities.index(i))\r\n",
        "    label[node_index[nodeId]]=labeller(u)\r\n",
        "  return adj_matrix, degree_matrix, label"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5U_8-RMqjMj"
      },
      "source": [
        "**Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxxwn02DmzKj"
      },
      "source": [
        "def trainData(label):\r\n",
        "  k = label.shape[0]\r\n",
        "  testingNum = math.floor(k*0.2)\r\n",
        "  testIndex = random.sample(range(0, k), testingNum)\r\n",
        "  training_label = np.zeros((k, 2**n-1))\r\n",
        "  for i in range(k):\r\n",
        "    training_label[i] = label[i]\r\n",
        "  training_label[testIndex] = [None]\r\n",
        "  print(label[testIndex[1]])\r\n",
        "  print(testIndex[1])\r\n",
        "  return training_label, testIndex"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHPzmwiHqwUP"
      },
      "source": [
        "**Building GNN, training, and testing it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-zplaQNyqGJa",
        "outputId": "bbfe7780-95c6-4cb1-f20d-05c3e3fa904b"
      },
      "source": [
        "def gnn(adj_matrix, degree_matrix, label, feature_matrix, test_label, test_index, train_index):\r\n",
        "    features = tf.placeholder(tf.float32, shape = ((None,len(feature_matrix))))\r\n",
        "    adjacency = tf.placeholder(tf.float32, shape = ((None,None)))\r\n",
        "    degree = tf.placeholder(tf.float32, shape = ((None,None)))\r\n",
        "    labels = tf.placeholder(tf.float32, shape = ((None,2**n-1)))\r\n",
        "    weights1 = tf.Variable(tf.random_normal([len(feature_matrix),512], stddev = 1))\r\n",
        "    weights2 = tf.Variable(tf.random_normal([512, 2**n-1], stddev = 1))\r\n",
        "    trainIndex = tf.placeholder(tf.int32, shape = ((len(train_index))))\r\n",
        "#Defining GCN layer\r\n",
        "    def layer(features, adjacency, degree, weights):\r\n",
        "        with tf.name_scope('gcn_layer'):\r\n",
        "            d_ = tf.pow(tf.matrix_inverse(degree), 0.5)\r\n",
        "            y = tf.matmul(d_, tf.matmul(adjacency, d_))\r\n",
        "            kernel = tf.matmul(features, weights)\r\n",
        "            return tf.nn.relu(tf.matmul(y, kernel))\r\n",
        "\r\n",
        "#Building with GCN layer        \r\n",
        "    hidden1 = layer(features, adjacency, degree, weights1)\r\n",
        "    hidden1 = tf.layers.dropout(hidden1, rate=0.5)\r\n",
        "    model = layer(hidden1, adjacency, degree, weights2)\r\n",
        "    training_output = tf.gather(model, trainIndex)\r\n",
        "\r\n",
        "#Selecting training labels\r\n",
        "    training_label = label[train_index]\r\n",
        "\r\n",
        "#Defining loss function and optimizer\r\n",
        "    with tf.name_scope('loss'):\r\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = training_output, labels = training_label.astype(np.float32)))\r\n",
        "        train_op = tf.train.AdamOptimizer(0.01, 0.90).minimize(loss)\r\n",
        "\r\n",
        "    init = tf.global_variables_initializer()\r\n",
        "\r\n",
        "    sess = tf.Session()\r\n",
        "    sess.run(init)\r\n",
        "\r\n",
        "    test_label = test_label[test_index]\r\n",
        "\r\n",
        "    b = np.argmax(test_label, axis = 1)\r\n",
        "#training up to 200 epochs\r\n",
        "    for i in range(200):\r\n",
        "        _, cost = sess.run([train_op, loss], feed_dict = {features: feature_matrix, adjacency: adj_matrix, degree: degree_matrix, labels: label, trainIndex: train_index})\r\n",
        "        if(i%10 == 0):\r\n",
        "            predict = sess.run(tf.nn.softmax(model), feed_dict = {features: feature_matrix, adjacency: adj_matrix, degree: degree_matrix, labels: test_label})\r\n",
        "            test_res = predict[test_index]\r\n",
        "            a = np.argmax(test_res, axis = 1)\r\n",
        "            #checking test accuracy at every 10th epoch\r\n",
        "            print(\"test accuracy: \", np.sum(a == b)/len(test_index))\r\n",
        "    return test_res,test_label\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "  n_communities,graph = loadData(labelfile, graphfile)\r\n",
        "  adj_matrix, degree_matrix, label = preprocessingData(graph, n_communities)\r\n",
        "  train_label, test_index = trainData(label)\r\n",
        "  #calculating feature matrix from adj_matrix\r\n",
        "  feature_matrix = np.eye(len(adj_matrix))\r\n",
        "  adj_matrix = adj_matrix + feature_matrix\r\n",
        "  train_index = []\r\n",
        "  for i in range(len(adj_matrix)):\r\n",
        "    if i not in test_index:\r\n",
        "      train_index.append(i)\r\n",
        "  test_res,test_label= gnn(adj_matrix, degree_matrix, train_label, feature_matrix, label, test_index, train_index)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.06578947368421052\n",
            "test accuracy:  0.7368421052631579\n",
            "test accuracy:  0.8026315789473685\n",
            "test accuracy:  0.8289473684210527\n",
            "test accuracy:  0.8289473684210527\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8289473684210527\n",
            "test accuracy:  0.8289473684210527\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n",
            "test accuracy:  0.8421052631578947\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}